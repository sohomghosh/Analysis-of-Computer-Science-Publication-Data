fit1=lm(medv~lstat,data=Boston)
fit1
?Boston
Boston
Boston[1:1]
package(neuralnet)
install.packages("neuralnet")
package(neuralnet)
library(neuralnet)
install.package(grid)
package.install(grid)
install.packages("neuralnet")
ann_model <- neuralnet( y ~ x1 + x2 + x3, data=as.data.frame(cbind(y,x1,x2, x3)), hidden = 1)
import(neuralnet)
require(neuralnet)
require(grid)
require(MASS)
require(neuralnet)
ann_model <- neuralnet( y ~ x1 + x2 + x3, data=as.data.frame(cbind(y,x1,x2, x3)), hidden = 1)
x=c(2,7,5)
x
y=seq(from=4,length=3,by=3)
?seq
y
y=seq(from=4,length=3,by=4)
y
x[-2]
x[1]
x[-c(1,2)]
x
c(1,2)
library(MASS)
library(ISLR)
names(Boston)
?Boston
plot(medv~lstat,Boston)
?Boston
a<-read.csv("MyData.csv")
a
lm(Beautifulness~Complexity,a)
lm(Beautifulness~Complexion,a)
lm(Beautifulness~Complextion,a)
?lm
lm(x~y)
plot(medv~lstat,Boston)
fit1=lm(medv~lstat,data=Boston)
fit1
x<-c(1,2,3)
y<-(2,3,6)
y<-c(2,3,6)
lm(x~y)
?lm
lm(x~y)
lm(x~y)
summary(lm(x~y))
v<-lm(Beautifulness~Complextion,a)
v
lm(x~y)
summary(lm(x~y))
summary(fit1)
x<-c(1,2,3)
y<-c(.5,1,1.5)
plot(x,y)
y<-c(1.5,1,.5)
plot(x,y)
lm(x~y)
y<-c(4,2,1)
f<-lm(x~y)
f
abline(f)
abline(f,col="red")
plot(x,y)
abline(f,col="red")
abline(f)
confint(fit1)
confit(f)
fit<-lm(y~x)
confit(fit)
confint(fit)
predict(fit1,data.frame(lstat=c(5,10,15)),interval="confidence")
predict(fit,data.frame(c(4,5)))
predict(fit,data.frame(c(4)))
?predict
predict(fit)
predict(fit,4)
predict(fit,y=4)
predict(fit,x=4)
predict(fit,data.frame(x=4))
predict(fit,data.frame(x=5))
predict(fit,data.frame(x=4.5))
predict(fit,data.frame(x=c(4.5,5,6))
)
fit2=lm(medv~lstat+age,data=Boston)
summary(fit2)
fit3=lm(medv~.,Boston)
par(mfrow=c(2,2))
plot(fit3)
z<-c(3,4,5)
fi<-lm(x+z~y)
fi
plot(x,y,z)
plot(x,y)
abline(fi)
abline(fi,col="red")
par(mfrow=c(1,1))
plot(x,y)
abline(fi,col="red")
plot(f3)
plot(fit3)
plot(f3)
plot(fit3)
plot(fi)
fit3
plot(x,y)
plot(y,x)
a
lm(Beautifulness~Complextion)
lm(Beautifulness~Beautifulness+Complextion+Smartness+Look+Attitude+Age+Knowledge)
lm(Beautifulness~Beautifulness+Complextion+Smartness+Look+Attitude+Age+Knowledge,data=a)
lm(Beautifulness~.,data=a)
lm(Beautifulness~Complextion+Smartness+Look+Attitude+Age+Knowledge,data=a)
fit5=lm(medv~lstat*age,Boston)
summary(fit5)
lm(Beautifulness~.,data=a)
fit5=lm(medv~lstat*age,Boston)
summary(fit5)
fit6=lm(medv~lstat +I(lstat^2),Boston); summary(fit6)
points(lstat,fitted(fit6),col="red",pch=20)
attach(Boston)
points(lstat,fitted(fit6),col="red",pch=20)
par(mfrow=c(1,1))
plot(medv~lstat)
points(lstat,fitted(fit6),col="red",pch=20)
fit7=lm(medv~poly(lstat,4))
points(lstat,fitted(fit7),col="blue",pch=20)
plot(1:20,1:20,pch=1:20,cex=2)
plot(medv~lstat)
abline(fit6)
fix(Carseats)
fit1=lm(Sales~.+Income:Advertising+Age:Price,Carseats)
contrasts(Carseats$ShelveLoc)
Shelveloc
fix(Carseats)
summary(Carseats)
a=read.csv("mobile.csv")
summary(a)
summary(read.csv("mobile.csv"))
fix(Carseats)
contrasts(Income)
contrasts(Carseats$Income)
fix(Carseats)
contrasts(Urban)
contrasts(Carseata$Urban)
contrasts(Carseats$Urban)
contrasts(Carseats$Urban,Carseats$Income)
require(ISLR)
names(Smarket)
?Smarket
pairs(Smarket,col=Smarket$Direction)
?Smarket
pairs(Smarket,col=Smarket$Direction)
pairs(Smarket)
pairs(Smarket,col=Smarket$Direction)
?pairs
pairs(Smarket,col=Smarket$Lag3)
pairs(Smarket,col=Smarket$Today)
smarket$Direction
?smarket
Smarket$Direction
Smarket$Today
fit(Smarket)
fix(Smarket)
pairs(Smarket,col=Smarket$Volume)
pairs(Smarket,col=20)
pairs(Smarket)
pairs(a)
a<-read.csv("Mydata.csv")
pairs(a)
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial)
summary(glm.fit)
glm.probs=predict(glm.fit,type="response")
glm.probs[1:5]
glm.pred=ifelse(glm.probs>0.5,"Up","Down")
attach(Smarket)
table(glm.pred,Direction)
table(Direction,Lag5)
table(x,y)
table(x,y,z)
train = Year<2005
glm.fit=glm(Direction~Lag1+Lag2,
data=Smarket,family=binomial, subset=train)
lda.fit=lda(Direction~Lag1+Lag2,data=Smarket, subset=Year<2005)
lda.fit
library(class)
?knn
library(class)
?knn
attach(Smarket)
Xlag=cbind(Lag1,Lag2)
train=Year<2005
knn.pred=knn(Xlag[train,],Xlag[!train,],Direction[train],k=1)
table(knn.pred,Direction[!train])
mean(knn.pred==Direction[!train])
knn.pred=knn(Xlag[train,],Xlag[!train,],Direction[train],k=1)
knn.pred=knn(Xlag[train,],Xlag[!train,],Direction[train],k=3)
knn.pred
table(knn.pred,Direction[!train])
knn.pred=knn(Xlag[train,],Xlag[!train,],Direction[train],k=1)
table(knn.pred,Direction[!train])
knn.pred=knn(Xlag[train,],Xlag[!train,],Direction[train],k=5)
table(knn.pred,Direction[!train])
knn.pred=knn(Xlag[train,],Xlag[!train,],Direction[train],k=2)
table(knn.pred,Direction[!train])
?cv.glm
?cv.glm
require(ISLR)
require(boot)
?cv.glm
require(ISLR)
require(boot)
cv.error10=rep(0,5)
for(d in degree){
glm.fit=glm(mpg~poly(horsepower,d), data=Auto)
cv.error10[d]=cv.glm(Auto,glm.fit,K=10)$delta[1]
}
degree=1:5
for(d in degree){
glm.fit=glm(mpg~poly(horsepower,d), data=Auto)
cv.error10[d]=cv.glm(Auto,glm.fit,K=10)$delta[1]
}
lines(degree,cv.error10,type="b",col="red")
?regsubsets
library(leaps)
install.packages("leaps")
library(leaps)
?regsubsets
?kmeans
?kmeans
pr.out=prcomp(a , scale=TRUE)
a<-read.csv("Myfile.csv")
a<-read.csv("MyData.csv")
pr.out=prcomp(a , scale=TRUE)
b<-na.omit(a)
pr.out=prcomp(b , scale=TRUE)
pr.out
names(pr.out)
?prcom
?prcomp
biplot(pca.out, scale=0)
pca.out=prcomp(USArrests, scale=TRUE)
pca.out
names(pca.out)
biplot(pca.out, scale=0)
set.seed(101)
set.seed(101)
set.seed(101)
x=matrix(rnorm(100*2),100,2)
?kmeans
x
xmean=matrix(rnorm(8,sd=4),4,2)
xmean
which=sample(1:4,100,replace=TRUE)
which
plot(x,col=which,pch=19)
km.out=kmeans(x,4,nstart=15)
km.out
plot(x,col=km.out$cluster,cex=2,pch=1,lwd=2)
points(x,col=which,pch=19)
points(x,col=c(4,3,2,1)[which],pch=19)
Mydata<-read.csv("Rdata.csv")
newdata<-mydata[,2:3]
newdata<-Mydata[,2:3]
print(newdata)
plot(newdata$complextion,newdata$smartness)
a<-Mydata[,2]
a
b<-Mydata[,3]
plot(a,b)
kc <- kmeans(newdata, 3)
summary(kc)
plot(newdata[c("Complextion", "Smartness")], col=kc$cluster)
points(kc$centers[,c("Complextion", "Smartness")], col=1:3, pch=8, cex=2)
kc <- kmeans(newdata, 8)
summary(kc)
plot(newdata[c("Complextion", "Smartness")], col=kc$cluster)
points(kc$centers[,c("Complextion", "Smartness")], col=1:3, pch=8, cex=2)
?hclust
x
hc.complete=hclust(dist(mydata),method="complete")
hc.complete=hclust(dist(newdata),method="complete")
plot(hc.complete)
hc.single=hclust(dist(x),method="single")
plot(hc.single)
hc.complete=hclust(dist(x),method="complete")
plot(hc.complete)
hc.average=hclust(dist(x),method="average")
plot(hc.average)
hc.cut=cutree(hc.complete,4)
table(hc.cut,which)
table(hc.cut,km.out$cluster)
plot(hc.complete,labels=which)
hc.cut=cutree(hc.complete,4)
hc.cut
plot(hc.cut)
table(hc.cut,km.out$cluster)
?rand
?sample
sample(newdata, 10, replace = FALSE, prob = NULL)
sample(newdata, 10)
sample(newdata, 2, replace = FALSE, prob = NULL)
sample(newdata, 1, replace = FALSE, prob = NULL)
sample(newdata, 1, replace = FALSE, prob = NULL)
sample(newdata, 1, replace = FALSE, prob = NULL)
sample(newdata[1:100], 10, replace = FALSE, prob = NULL)
sample(newdata[1:100,], 10, replace = FALSE, prob = NULL)
getdata(newdata,10)
llibrary(sampling)
library(sampling)
install.packages("sampling")
library(sampling)
getdata(newdata,10)
getdata(newdata,10)
getdata(newdata,10)
getdata(newdata,1)
sample(newdata)
sample(newdata,4)
newdata[sample(nrow(newdata),3),]
points(kc$centers[,c("Complextion", "Smartness")], col=1:3, pch=8, cex=2)
plot(newdata[c("Complextion", "Smartness")], col=kc$cluster)
library(e1071)
svmfit=svm(Complextion~.,data=newdata[c("Complextion", "Smartness")],kernel="linear",cost=10,scale=FALSE)
print(svmfit)
plot(svmfit,newdata[c("Complextion", "Smartness"))
plot(svmfit,newdata[c("Complextion", "Smartness")])
plot(svmfit,newdata[c("Complextion", "Smartness")])
a<-predict(svmfit,4)
require(ISLR)
require(tree)
attach(Carseats)
hist(Sales)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats, High)
```
Now we fit a tree to these data, and summarize and plot it. Notice that we have to _exclude_ `Sales` from the right-hand side of the formula, because the response is derived from it.
```{r}
tree.carseats=tree(High~.-Sales,data=Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
```
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
cv.carseats
rattle()
library("rattle")
rattle()
library("rattle")
rattle()
library("rattle")
ratle()
rattle()
library("rattle")
rattle()
a<-read.csv("C:/Users/Sohom Ghosh/Desktop/Gramener/GramenerTraining.csv")
a[c="State"]
a["State"]
summary(a["State"])
summary(a["State"])
rattle()
library("rattle")
rattle()
install.packages("monmlp")
install.packages("rsnns")
install.packages("RSNNS")
?monmlp
?save
??save
library(rattle)
rattle()
c<-75.3
typeof(c)
typeof(grade<-"B")
str(1<-as.factor("A+"))
str(lgrade<-as.factor("A+"))
?str
5/5
5//5
5%5
5%%5
sqrt(2)
17->z
z
1/0
1/Inf
Inf-Inf
Nan/NaN
NaN/NaN
a<-(1:10,2)
a<-range(1:10,2)
a
a<-seq(1:10,2)
a<-(1,4,3)
a<-c(1,4,3)
range(a)
5==5
5>5
x = c(1, 2, 3, 4)
x < 2 | x > 3
all(x>0)
any(x>0)
any(x>0)
?mode
ls()
library(igraph)
a<-make_ring(10)
A
A <- matrix(c(0,1,0,0,0,0,
1,0,1,0,0,0,
0,1,0,1,1,1,
0,0,1,0,1,0,
0,0,1,1,0,1,
0,0,1,0,1,0 ),6,6, byrow= TRUE)
g <- graph.adjacency(A)
g
closeness(g)
betweenness(g)
degree_distribution(g)
degree(g)
layout1 <- layout.fruchterman.reingold(g)
plot(g, layout=layout1)
readinteger <- function()
{
n <- readline(prompt="Enter an integer: ")
return(as.integer(n))
}
print(readinteger())
x<-scan()
x
readline()
require(igraph)
g<-make_ring(10)
require(gdata)
getwd()
a<-read.xls("C:/Users/Sohom Ghosh/Desktop/WORK!!!!/1DB_ISI_4thYr/4thYr-ISI/granerer/others/Garner_DB.xlsx", sheet = 1, header = TRUE)
a
b<-data.frame(a)
edit(b)
library(gdata)
a<-read.xls(C:/Users/Sohom Ghosh/Desktop/WORK!!!!/1DB_ISI_4thYr/4thYr-ISI/granerer/others/Garner_DB.xlsx", sheet = 1, header = TRUE)
a<-read.xls("C:/Users/Sohom Ghosh/Desktop/WORK!!!!/1DB_ISI_4thYr/4thYr-ISI/granerer/others/Garner_DB.xlsx", sheet = 1, header = TRUE")
""
a<-read.xls("C:/Users/Sohom Ghosh/Desktop/WORK!!!!/1DB_ISI_4thYr/4thYr-ISI/granerer/others/Garner_DB.xlsx", sheet = 1, header = TRUE)
a
library("Rcmdr")
test1
test1<-c(1,2,5)
test2<-c(3,4,6)
t.test(test1,test2)
t.test(rnorm(1e7,mean=0,sd=1),rnorm(1e7,mean=0,sd=1),mu=0)
wt<-c(56,68,74,57,87.43.21)
wt<-c(56,68,74,57,87,43,21)
wt
wt<-as.data.frame(wt)
install.packages("RCurl")
install.packages("RCurl")
library(RCurl)
url <- "http://www.basketball-reference.com/boxscores/201506140GSW.html"
data <- readLines(url)
library(rvest)
install.packages("rvest")
library(rvest)
page <- read_html(url)
library(rvest)
page <- read_html(url)
page <- read_html(url)
library(RCurl)
url <- "http://www.basketball-reference.com/boxscores/201506140GSW.html"
data <- readLines(url)
library(rvest)
page <- read_html(url)
install.packages("xml2")
library(rattle)
rattle()
rattle()
setwd("C:/Users/Sohom Ghosh/Desktop/K-ShareProject")
require(XML)
xmlfile=xmlParse("dblp50000.xml")
xmltop = xmlRoot(xmlfile)
xmlName(xmltop)
xmlSize(xmltop)
xmlName(xmltop[[1]])
xmltop[[1]]
xmltop[[2]]
xmltop[[1]][[1]]
tit<-getNodeSet(xmlfile,"/dblp/article/title")
yr<-getNodeSet(xmlfile,"/dblp/article/year")
setwd("C:/Users/Sohom Ghosh/Desktop/K-ShareProject")
require(XML)
setwd("C:/Users/Sohom Ghosh/Desktop/programming_softs/MOOCsResearch/KshareAcademyBigData/K-shareProject")
require(XML)
xmlfile=xmlParse("dblp50000.xml")
xmltop = xmlRoot(xmlfile)
xmlName(xmltop)
xmlSize(xmltop)
xmlName(xmltop[[1]])
xmltop[[1]]
xmltop[[2]]
xmltop[[1]][[1]]
tit<-getNodeSet(xmlfile,"/dblp/article/title")
yr<-getNodeSet(xmlfile,"/dblp/article/year")
tit
yr
